<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="内容介绍hive on spark的调优,那必然涉及到这一系列框架的内存模型。本章就是来讲一下这些框架的内存模型。hive on spark的任务，从开始到结束。总共涉及了3个框架。分别是：yarn、hive、spark其中，hive只是一个客户端的角色。就不涉及任务运行时的内存。所以这里主要讲的yarn和spark的内存模型。其中，由于spark是运行在yarn的container中。所以我们从">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2024/05/08/hive%20on%20spark%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.18136064/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="内容介绍hive on spark的调优,那必然涉及到这一系列框架的内存模型。本章就是来讲一下这些框架的内存模型。hive on spark的任务，从开始到结束。总共涉及了3个框架。分别是：yarn、hive、spark其中，hive只是一个客户端的角色。就不涉及任务运行时的内存。所以这里主要讲的yarn和spark的内存模型。其中，由于spark是运行在yarn的container中。所以我们从">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090836602-581162753.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090713642-541615028.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090813834-27685100.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090824971-810464218.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090923987-1280164441.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090934442-91094235.png">
<meta property="og:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090943688-1622182919.png">
<meta property="article:published_time" content="2024-05-08T01:31:21.691Z">
<meta property="article:modified_time" content="2024-04-21T08:01:17.501Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090836602-581162753.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-hive on spark内存模型.18136064" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/05/08/hive%20on%20spark%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.18136064/" class="article-date">
  <time class="dt-published" datetime="2024-05-08T01:31:21.691Z" itemprop="datePublished">2024-05-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="内容介绍"><a href="#内容介绍" class="headerlink" title="内容介绍"></a>内容介绍</h1><p>hive on spark的调优,那必然涉及到这一系列框架的内存模型。本章就是来讲一下这些框架的内存模型。<br>hive on spark的任务，从开始到结束。总共涉及了3个框架。分别是：yarn、hive、spark<br>其中，hive只是一个客户端的角色。就不涉及任务运行时的内存。所以这里主要讲的yarn和spark的内存模型。<br>其中，由于spark是运行在yarn的container中。所以我们从外到内。先将yarn的资源分配。后讲spark的内存模型。</p>
<h2 id="hive-on-spark提交流程"><a href="#hive-on-spark提交流程" class="headerlink" title="hive on spark提交流程"></a>hive on spark提交流程</h2><h3 id="hive阶段"><a href="#hive阶段" class="headerlink" title="hive阶段"></a>hive阶段</h3><p>首先上场的是hive框架。当我们写了一个SQL语句的时候，会被hive进行解析（hive用的SQL解析框架是Antlr4）。解析的流程是：</p>
<ul>
<li>解析器将SQL解析成AST（抽象语法树）</li>
<li>逻辑生成器</li>
<li>逻辑优化器 (这里主要做一些谓词下推的操作)</li>
<li>物理生成器</li>
<li>物理优化器(这里则是做基于代价的优化，简称CBO)</li>
<li>执行器 (在这里就会将Spark任务提交给yarn)<br>这里是进行物理优化器的地方，可以看见，从这里开始，就已经根据引擎的不同，进行不同的优化了。<br><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090836602-581162753.png" alt="img"><br>此处就是执行器<br><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090713642-541615028.png" alt="img"><br>我们进去之后就可以看见 提交Spark任务<br><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090813834-27685100.png" alt="img"><br>我们可以在这里看见，把job上传到yarn上，并且添加了一些监听器来获取job的状态<br><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090824971-810464218.png" alt="img"></li>
</ul>
<p>这样之后，SQL就会被转为Spark一系列的RDD。</p>
<h3 id="yarn资源"><a href="#yarn资源" class="headerlink" title="yarn资源"></a>yarn资源</h3><p>在hive中，我们已经把spark job提交到yarn上面。现在我们就来看一下yarn的内存模型。</p>
<p>yarn的组成很简单，有ResourceManager和NodeManager，其中ResourceManager是大哥。对客户端传来的请求做处理。NodeManager是小弟。负责运行任务。<br>就此而言，我们就可以做出一个简单的判断：对于资源（内存和CPU）的分配，我们要多给NodeManager资源。ResourceManager无需很多的资源。因为ResourceManager仅仅是处理客户端的请求和管理NodeManager。并不进行任务的计算。<br>NodeManager里面是很多的Container，我们的Spark任务就是跑在Container里面的。</p>
<h4 id="yarn中关于资源的参数"><a href="#yarn中关于资源的参数" class="headerlink" title="yarn中关于资源的参数"></a>yarn中关于资源的参数</h4><p>由于spark任务是跑在NodeManager下的Container中。所以我们可以对NodeManager和Contaniner进行参数的调整（资源的配置）</p>
<h5 id="NodeManager的参数"><a href="#NodeManager的参数" class="headerlink" title="NodeManager的参数"></a>NodeManager的参数</h5><ul>
<li>yarn.nodemanager.resource.memory-mb : NodeManager可以给Container分配内存</li>
<li>yarn.nodemanager.resource.cpu-vcores ：NodeManager可以给Container分配的虚拟核数（因为不同的CPU可能计算能力不同。有可能一个i7的CPU顶两个i5的。所以就可以把i7的cpu映射为两个虚拟核。这样的话，就不会出现因为CPU的差异，而导致的：相同的任务跑多次。每次所耗的时间相差特别大。）</li>
</ul>
<h5 id="Container的参数"><a href="#Container的参数" class="headerlink" title="Container的参数"></a>Container的参数</h5><ul>
<li>yarn.scheduler.maximum-allocation-mb ： 单个Container可以使用的最大内存</li>
<li>yarn.scheduler.minimum-allocation-mb ： 单个Container可以使用的最小内存</li>
</ul>
<h3 id="Spark资源"><a href="#Spark资源" class="headerlink" title="Spark资源"></a>Spark资源</h3><p>Spark的内存模型可以大致分为堆内内存和堆外内存<br><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090923987-1280164441.png" alt="img"></p>
<h4 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h4><p><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090934442-91094235.png" alt="img"><br>动态占用机制：简单的来说，</p>
<ul>
<li>当<strong>存储</strong>和<strong>执行</strong>的内存都不足时。<strong>存储</strong>会存放到硬盘。</li>
<li>当<strong>存储</strong>占用了<strong>执行</strong>的内存后，<strong>执行</strong>想收回内存时。<strong>存储</strong>会将占用的部分转存到硬盘。归还内存</li>
<li>当<strong>执行</strong>占用了<strong>存储</strong>的内存后，<strong>存储</strong>想收回内存时，<strong>执行</strong>无法归还内存。需要等到<strong>执行</strong>使用完毕，才可以归还内存。（朴素的想一想，比较计算重要。不能停止，只好让<strong>存储</strong>等一等。等<strong>执行</strong>计算完毕，再归还内存）</li>
</ul>
<h4 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h4><p><img src="https://img2023.cnblogs.com/blog/2580584/202404/2580584-20240416090943688-1622182919.png" alt="img"></p>
<p>在默认情况下，堆外内存并不启用。可以通过<code>spark.memory.offHeap.enabled</code>开启。<br>堆外内存的大小由<code>spark.memory.offHeap.size</code>指定。<br>堆外内存的优点：</p>
<ul>
<li>Spark直接操作系统堆外内存，减少了不必要的内存开销，和频繁的GC的扫描和回收，提高了性能</li>
<li>可以被精准的申请和释放。（因为堆内内存是由JVM管理的。所以无法实现精准的释放）</li>
</ul>
<h3 id="整合yarn和Spark"><a href="#整合yarn和Spark" class="headerlink" title="整合yarn和Spark"></a>整合yarn和Spark</h3><p>我们先对一台服务器的资源配置做出假设，并根据这些假设，对资源进行合理的分配。</p>
<p><strong>服务器的资源情况：</strong> 32核CPU，128G内存</p>
<p>因为我们的服务器不可能只是为yarn一个框架提供资源。其他的框架也需要资源。所以我们可用分配给yarn的资源为：16核CPU，64G内存</p>
<p>Spark任务分为Driver和Executor。</p>
<h4 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h4><p>由于 Spark 的Executor的CPU建议数量是4~6个。 然后服务器中yarn可用的CPU资源数是16。</p>
<p>16&#x2F;4&#x3D;4;16&#x2F;5&#x3D;3…1;16&#x2F;6&#x3D;2…4;可以看出。单个Executor的CPU核数为5、6的时候，都会有一些CPU核未使用上，造成CPU的浪费。所以我们选取 单个Executor的CPU核数为4。然后我们根据1CU原则（1个CPU对应4G内存）。所以Executor的内存数为4*4G。</p>
<p><strong>单个Executo资源情况：</strong> 4核CPU，16G内存。</p>
<p>根据资源的配置情况可知， 一个节点能运行的Executo数量为 4</p>
<p>这样，我们对于单个Executor 的资源分配好了。我们再来看Executor内部的内存分配。</p>
<p>由上面的Spark的内存模型可知。Spark的内存分为<strong>堆内</strong>和<strong>堆外</strong>内存。在默认情况下  堆外内存&#x3D;堆内内存*0.1 (<code>spark.executor.memoryOverhead</code>&#x3D;<code>spark.executor.memory</code>*0.1)<br>所以简单的计算一下就可知：</p>
<ul>
<li><code>spark.executor.memoryOverhead</code>&#x3D;$\frac{1}{11}*16G(单个Executor的可用的总内存)$</li>
<li><code>spark.executor.memory</code>&#x3D;$\frac{10}{11}*16G(单个Executor的可用总内存)$</li>
</ul>
<p>当然，很多情况下这个结果都不是整数。所以计算出结果后，再进行一些个人的调整就好。</p>
<p>在这里Executor内部实际的内存分配情况如下：</p>
<p><code>spark.executor.memoryOverhead</code>&#x3D;2G</p>
<p><code>spark.executor.memory</code>&#x3D;14G</p>
<p>到这里，我们给各个组件的资源就已经分配完毕了。<br>下面我们来从Spark任务的角度谈一下，一个Spark任务，应该使用多少个Executor合适。</p>
<p>对于一个Spark任务的Executor数量，有<strong>静态分配</strong>和<strong>动态分配</strong>两种选择。<br>我们当然是选择<strong>动态分配</strong>。（因为<strong>静态分配</strong>相比于<strong>动态分配</strong>，更容易造成资源的浪费或者Spark任务资源的不足。）</p>
<p><strong>动态分配：</strong> 根据Spark任务的工作负载，可用动态的调整所占用的资源（Executor的数量）。需要时申请，不需要时释放。下面是<strong>动态分配</strong>的一些参数的设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动动态分配</span></span><br><span class="line">spark.dynamicAllocation.enabled    true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启用Spark shuffle服务</span></span><br><span class="line">spark.shuffle.service.enabled    true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Executor个数初始值</span></span><br><span class="line">spark.dynamicAllocation.initialExecutors    1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Executor个数最小值</span></span><br><span class="line">spark.dynamicAllocation.minExecutors    1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Executor个数最大值</span></span><br><span class="line">spark.dynamicAllocation.maxExecutors    12</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Executor空闲时长，若某Executor空闲时间超过此值，则会被关闭</span></span><br><span class="line">spark.dynamicAllocation.executorIdleTimeout    60s</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积压任务等待时长，若有Task等待时间超过此值，则申请启动新的Executor</span></span><br><span class="line">spark.dynamicAllocation.schedulerBacklogTimeout    1s</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">spark shuffle老版本协议</span></span><br><span class="line">spark.shuffle.useOldFetchProtocol true</span><br></pre></td></tr></table></figure>

<p>$\color{ForestGreen}{为什么启动Spark的shuffle}$：作用是将map的输出文件落盘。供后续的reduce使用。</p>
<p>$\color{ForestGreen}{为什么落盘}$：因为如果map的输出的文件不落盘。map就不会被释放。也就无法释放这个空闲的Executor。只有将输出文件落盘后，这个Executor才会被释放。</p>
<h4 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h4><p>Driver主要的配置参数有<code>spark.driver.memory</code>和<code>spark.driver.memoryOverhead</code>。</p>
<p>此处<code>spark.driver.memory</code>和<code>spark.driver.memoryOverhead</code>的分配的内存比例和Executor一样。都是<code>spark.driver.memoryOverhead</code>&#x3D;<code>spark.driver.memory</code>*0.1</p>
<p>对于Driver的总内存，有一个经验公式：（假定<code>yarn.nodemanager.resource.memory-mb</code>设为$X$）</p>
<ul>
<li>若$X&gt;50G$，则Driver设为12G</li>
<li>若$12G&lt;X&lt;50G$，则Driver设为4G</li>
<li>若$1G&lt;X&lt;12G$，则Driver设为1G</li>
</ul>
<p>因为我们的<code>yarn.nodemanager.resource.memory-mb</code>&#x3D;64G。所以：</p>
<ul>
<li><code>spark.driver.memory</code> &#x3D; 10G</li>
<li><code>spark.driver.memoryOverhead</code> &#x3D; 2G</li>
</ul>
<h3 id="配置文件的设置"><a href="#配置文件的设置" class="headerlink" title="配置文件的设置"></a>配置文件的设置</h3><h4 id="spark-defaults-conf"><a href="#spark-defaults-conf" class="headerlink" title="spark-defaults.conf"></a>spark-defaults.conf</h4><p>配置文件的位置：<code>$HivE_HOME/conf/spark-defaults.conf</code></p>
<p>由于我们多个节点有Spark。所以可能会有一些疑问：$\color{ForestGreen}{这么多Spark，这么多配置文件，究竟是Spark任务运行的节点 的配置文件生效呢？还是Hive目录下的配置文件生效呢？}$<br>答案：当然是Hive目录下的配置文件生效。如果我们了解过Spark的任务提交流程就知道。当我们运行了一条命令行后。Spark-submit会解析参数。然后再向yarn提交请求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">spark.master                               yarn</span><br><span class="line">spark.eventLog.enabled                   true</span><br><span class="line">spark.eventLog.dir    hdfs://myNameService1/spark-history</span><br><span class="line">spark.executor.cores    4</span><br><span class="line">spark.executor.memory    14g</span><br><span class="line">spark.executor.memoryOverhead    2g</span><br><span class="line">spark.driver.memory    10g</span><br><span class="line">spark.driver.memoryOverhead    2g</span><br><span class="line">spark.dynamicAllocation.enabled  true</span><br><span class="line">spark.shuffle.service.enabled  true</span><br><span class="line">spark.dynamicAllocation.executorIdleTimeout  60s</span><br><span class="line">spark.dynamicAllocation.initialExecutors    1</span><br><span class="line">spark.dynamicAllocation.minExecutors  1</span><br><span class="line">spark.dynamicAllocation.maxExecutors  12</span><br><span class="line">spark.dynamicAllocation.schedulerBacklogTimeout 1s</span><br><span class="line">spark.shuffle.useOldFetchProtocol    true</span><br></pre></td></tr></table></figure>

<h4 id="spark-shullfe"><a href="#spark-shullfe" class="headerlink" title="spark-shullfe"></a>spark-shullfe</h4><p>Spark的shullfe会因为Cluster Manager（standalone、Mesos、Yarn）的不同而不同。<br>此处我们是yarn。</p>
<p>步骤如下：</p>
<ul>
<li>拷贝<code>$SPARK_HOME/yarn/spark-3.0.0-yarn-shuffle.jar</code>到<code>$HADOOP_HOME/share/hadoop/yarn/lib</code></li>
<li>向集群分发<code>$HADOOP_HOME/share/hadoop/yarn/lib/spark-3.0.0-yarn-shuffle.jar</code></li>
<li>修改<code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle,spark_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.spark_shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.spark.network.yarn.YarnShuffleService<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>分发<code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code></li>
<li>重启yarn</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/05/08/hive%20on%20spark%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.18136064/" data-id="clvx5areq00074wubb5id1lqr" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2024/05/08/hive%20on%20spark%20%E4%BC%98%E5%8C%96-SQL%E5%B1%82%E9%9D%A2.18172390/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/05/08/hive%20on%20spark%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.18136064/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/05/08/hive%20on%20spark%20%E4%BC%98%E5%8C%96-SQL%E5%B1%82%E9%9D%A2.18172390/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/05/08/Hadoop%20VERSION%E6%96%87%E4%BB%B6%E8%AF%AF%E5%88%A0.18178177/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/05/08/Flume%E5%92%8Ckafka%20produce%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE.18173908/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/05/08/Flink%E8%B0%83%E4%BC%98%E5%88%9D%E6%AC%A1%E7%AC%94%E8%AE%B0.18172373/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>